{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021e556c",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "71bf1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as op\n",
    "from pprint import pformat\n",
    "from typing import Iterator\n",
    "\n",
    "# EEG utilities\n",
    "import mne\n",
    "from mne.preprocessing import ICA, create_eog_epochs\n",
    "from pyprep.prep_pipeline import PrepPipeline\n",
    "from autoreject import get_rejection_threshold, validation_curve\n",
    "\n",
    "# BIDS utilities\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "from util.io.bids import DataSink\n",
    "from bids import BIDSLayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e54a7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '6', '3', '5', '2'] ['pitch'] [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "BIDS_ROOT = '../data/bids'\n",
    "DERIV_ROOT = op.join(BIDS_ROOT, 'derivatives')\n",
    "LOWPASS = 300\n",
    "FS = 2000\n",
    "REJECT_THRES = 5e-7 # 50 microvolts\n",
    "\n",
    "# Parse BIDS directory\n",
    "layout = BIDSLayout(BIDS_ROOT)\n",
    "subjects = layout.get_subjects()\n",
    "tasks = layout.get_tasks()\n",
    "runs = layout.get_runs()\n",
    "print(subjects, tasks, runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd30fe83",
   "metadata": {},
   "source": [
    "## Functions\n",
    "#### Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f2c13cf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KeyType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [82]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create Iterator object to loop over all files\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfpaths\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[43mKeyType\u001b[49m]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m subjects:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KeyType' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Iterator object to loop over all files\n",
    "KeType = Tuple[]\n",
    "def fpaths() -> Iterator[KeyType]:\n",
    "    for sub in subjects:\n",
    "        for task in tasks:\n",
    "            for run in runs:\n",
    "#                 bids_path = get_bids_path(bids_root, sub, task, run)\n",
    "#                 save_path = get_save_path(deriv_root, sub, task, run)\n",
    "#                 PREP_seed = int(str(sub) + str(run))\n",
    "#                 if op.isfile(bids_path):\n",
    "#                     yield (bids_path, save_path, PREP_seed)\n",
    "                key = (sub, task, run)\n",
    "                yield key\n",
    "\n",
    "def get_bids_path(bids_root, sub, task, run):\n",
    "    bids_path = BIDSPath(root = bids_root,\n",
    "                        subject = sub,\n",
    "                        task = task,\n",
    "                        run = run,\n",
    "                        datatype = 'eeg',\n",
    "                        )\n",
    "    return bids_path\n",
    "\n",
    "def import_bids_data(bids_path):\n",
    "    raw = read_raw_bids(bids_path, verbose = False)\n",
    "    raw = raw.pick_types(eeg = True)\n",
    "    return raw\n",
    "\n",
    "def set_electrode_positions(raw, montage_name, stim_channel):\n",
    "    dig = mne.channels.make_standard_montage(montage_name)\n",
    "    raw = raw.set_channel_types({stim_channel: 'stim'}) \n",
    "    raw = raw.set_montage(dig)\n",
    "    return raw\n",
    "\n",
    "def read_events(raw):\n",
    "    events, events_ids = mne.events_from_annotations(raw)\n",
    "    return events, events_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8a2aa",
   "metadata": {},
   "source": [
    "#### Resampling and PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f4c44b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(fs, events): # Resample to a more manageable speed\n",
    "    raw, events = raw.resample(fs, events = events)\n",
    "    return raw, events\n",
    "\n",
    "def run_PREP(raw, sub, run, LOWPASS): # Run PREP pipeline (notch, exclude bad channels, and re-reference)\n",
    "    raw.load_data()\n",
    "    seed = int(str(sub) + str(run))\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    lf = raw.info['line_freq']\n",
    "    prep_params = {\n",
    "        'ref_chs': 'eeg',\n",
    "        'reref_chs': 'eeg',\n",
    "        'line_freqs': np.arange(lf, LOWPASS, lf) if np.arange(lf, LOWPASS, lf).size > 0 else [lf]\n",
    "    }\n",
    "    prep = PrepPipeline(raw, prep_params, raw.get_montage(), ransac = False, random_state = sub_idx)\n",
    "    prep = prep.fit()\n",
    "\n",
    "    raw = prep.raw_eeg # replace raw with cleaned version\n",
    "    bads = prep.noisy_channels_original\n",
    "    return raw, bads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ed94d",
   "metadata": {},
   "source": [
    "#### Apply the following preprocessing steps to two copies of the data\n",
    "Split the data into two copies, one filtered more liberally for ICA so that high frequency noise can be detected, one band-pass filtered at the behaviorally relevant frequencies. All of the following preprocessing steps will be applied to each of the copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dcaa4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass(raw, l_freq, h_freq):\n",
    "    raw = raw.filter(l_freq = l_freq, h_freq = h_freq)\n",
    "    return raw\n",
    "\n",
    "def create_eogs(raw):\n",
    "    raw = mne.set_bipolar_reference(raw, anode = 'Fp1', cathode = 'FT10', ch_name = 'eog1', drop_refs = False)\n",
    "    raw = mne.set_bipolar_reference(raw, anode = 'Fp2', cathode = 'FT9', ch_name = 'eog2', drop_refs = False)\n",
    "    raw = raw.set_channel_types({'eog1': 'eog', 'eog2': 'eog'})\n",
    "    return raw\n",
    "\n",
    "def epoch(raw):\n",
    "    epochs = mne.Epochs(\n",
    "        raw, \n",
    "        events, \n",
    "        tmin = -0.2, \n",
    "        tmax = 0.250, \n",
    "        baseline = None, # do NOT baseline correct the trials yet; we do that after ICA\n",
    "        event_id = event_ids, # remember which epochs are associated with which condition\n",
    "        preload = True # keep data in memory\n",
    "    )\n",
    "    return epochs\n",
    "\n",
    "def compute_ICA(raw, epochs):\n",
    "    ica = ICA(n_components = 15, random_state = 0)\n",
    "    ice = ica.fit(epochs, picks = 'eeg')\n",
    "    return ica\n",
    "\n",
    "def apply_ICA(epochs_for_ica, epochs):\n",
    "    eog_indices, eog_scores = ice.find_bads_eog(epochs_for_ica, threshold = 1.96)\n",
    "    ica.exclude = eog_indices\n",
    "    epochs = ica.apply(epochs) # apply to aggressively filtered version of data\n",
    "    return epochs, ica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accecc66",
   "metadata": {},
   "source": [
    "#### Baseline correct and reject trials\n",
    "Back to applying preprocessing on only one copy of the data. ICA is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2dd36868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_correct(epochs):\n",
    "    epochs = epochs.pick_types(eeg = True) # change syntax?\n",
    "    epochs = epochs.apply_baseline((-0.2, 0.))\n",
    "    return epochs\n",
    "\n",
    "def reject_trials(threshold, epochs):\n",
    "    epochs = epochs.drop_bad(reject = {'eeg': threshold})\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ab9c1",
   "metadata": {},
   "source": [
    "#### Save results and generate report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4176e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_path(deriv_root, sub, task, run):\n",
    "    sink = DataSink(folder, 'preprocessing')\n",
    "\n",
    "    # save cleaned data\n",
    "    fpath = sink.get_path(\n",
    "                    subject = sub,\n",
    "                    task = task, \n",
    "                    run = run,\n",
    "                    desc = 'clean',\n",
    "                    suffix = 'epo', # this suffix is following MNE, not BIDS, naming conventions\n",
    "                    extension = 'fif.gz',\n",
    "                    )\n",
    "    return fpath\n",
    "\n",
    "def save_preprocessed_data(fpath, epochs):\n",
    "    epochs.save(fpath, overwrite = True)\n",
    "    \n",
    "def generate_report(fpath, epochs, ica, bads):\n",
    "    report = mne.Report(verbose = True)\n",
    "    report.parse_folder(op.dirname(fpath), pattern = '*epo.fif.gz', render_bem = False)\n",
    "\n",
    "    # Plot the ERP\n",
    "    fig_erp = epochs['50'].average().plot(spatial_colors = True)\n",
    "    report.add_figs_to_section(\n",
    "        fig_erp, \n",
    "        captions = 'Average Evoked Response', \n",
    "        section = 'evoked'\n",
    "    )\n",
    "\n",
    "    # Plot the excluded ICAs\n",
    "    if ica.exclude: # if we found any bad components\n",
    "        fig_ica_removed = ica.plot_components(ica.exclude)\n",
    "        report.add_figs_to_section(\n",
    "            fig_ica_removed, \n",
    "            captions = 'Removed ICA Components', \n",
    "            section = 'ICA'\n",
    "        )     \n",
    "    \n",
    "    # Format output\n",
    "    html_lines = []\n",
    "    for line in pformat(bads).splitlines():\n",
    "        html_lines.append('<br/>%s' % line) \n",
    "    html = '\\n'.join(html_lines)\n",
    "    report.add_htmls_to_section(html, captions = 'Interpolated Channels', section = 'channels')\n",
    "    report.add_htmls_to_section('<br/>threshold: {:0.2f} microvolts</br>'.format(thres['eeg'] * 1e6), \n",
    "                                captions = 'Trial Rejection Criteria', section = 'rejection')\n",
    "    report.add_htmls_to_section(epochs.info._repr_html_(), captions = 'Info', section = 'info')\n",
    "    report.save(op.join(sink.deriv_root, 'sub-%s.html'%sub), overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dac9da",
   "metadata": {},
   "source": [
    "## Preprocessing wrapper\n",
    "Since we have to loop over all the data files the section below will contain the for loop to wrap all the preprocessing functions contained in the subsequent sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bcc2ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['100', '150', '200', '250', '50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hv/vj9_d69170l26hyj9hqqj45h0000gn/T/ipykernel_16958/3664887899.py:12: RuntimeWarning: The unit for channel(s) Aux1 has changed from V to NA.\n",
      "  raw = raw.set_channel_types({'Aux1': 'stim'})\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m sub \u001b[38;5;241m=\u001b[39m subjects[sub_idx]\n\u001b[1;32m      3\u001b[0m task \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mrun\u001b[49m\u001b[43m[\u001b[49m\u001b[43msub_idx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Import data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m bids_path \u001b[38;5;241m=\u001b[39m get_bids_path(sub, task, run)\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# for sub_idx, sub in enumerate(subjects):\n",
    "# for bids_path, save_path, PREP_seed\n",
    "for (sub, task, run) in fpaths():\n",
    "#     sub = subjects[sub_idx]\n",
    "#     task = tasks[0]\n",
    "#     run = str(run[sub_idx])\n",
    "    \n",
    "    # Import data\n",
    "    bids_path = get_bids_path(sub, task, run)\n",
    "    if ~op.isfile(bids_path) # skip if file doesn't exist\n",
    "        continue\n",
    "    raw = import_bids_data(bids_path)\n",
    "    events, event_ids = read_events(raw)\n",
    "#     raw = set_electrode_positions(raw, 'standard_1020', 'Aux1')\n",
    "    dig = mne.channels.make_standard_montage('standard_1020')\n",
    "    raw = raw.set_channel_types({'Aux1': 'stim'})\n",
    "    raw = raw.set_montage(dig)\n",
    "    \n",
    "#     # Make copy of unprocessed raw data for later comparison\n",
    "#     raw_unprocessed = raw.copy()\n",
    "    \n",
    "#     # Resampling and PREP\n",
    "#     raw, events = resample(FS, events)\n",
    "#     raw, bads = run_PREP(raw, sub, run, LOWPASS)\n",
    "    \n",
    "#     # Apply the following preprocessing steps to two copies of the data\n",
    "#     raw_for_ica = bandpass(l_freq = 1., h_freq = 1000)\n",
    "#     raw = bandpass(l_freq = 30, h_freq = 270)\n",
    "    \n",
    "#     raw_for_ica = create_eogs(raw_for_ica)\n",
    "#     raw = create_eogs(raw)\n",
    "    \n",
    "#     epochs_for_ica = epoch(raw_for_ica)\n",
    "#     epochs = epoch(raw)\n",
    "    \n",
    "#     ica = compute_ICA(epochs_for_ica) # run ICA on less aggressively filtered data\n",
    "#     epochs, ica = apply_ICA(epochs_for_ica, epochs) # apply ICA on more aggressively filtered data\n",
    "    \n",
    "#     # Baseline correct and reject trials\n",
    "#     epochs = baseline_correct(epochs)\n",
    "#     epochs = reject_trials(REJECT_THRES, epochs)\n",
    "    \n",
    "#     # Save results and generate report\n",
    "#     fpath = get_save_fpath(DERIV_ROOT)\n",
    "#     save_preprocessed_data(fpath, epochs)\n",
    "#     generate_report(fpath, epochs, ica, bads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cb43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
